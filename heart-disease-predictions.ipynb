{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:09.977476Z","iopub.execute_input":"2022-01-09T12:39:09.977761Z","iopub.status.idle":"2022-01-09T12:39:09.991487Z","shell.execute_reply.started":"2022-01-09T12:39:09.977728Z","shell.execute_reply":"2022-01-09T12:39:09.990601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries and dependencies\nimport pandas as pd\nimport numpy as np\nimport warnings \nimport seaborn as sns\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:09.993356Z","iopub.execute_input":"2022-01-09T12:39:09.993995Z","iopub.status.idle":"2022-01-09T12:39:10.1513Z","shell.execute_reply.started":"2022-01-09T12:39:09.99395Z","shell.execute_reply":"2022-01-09T12:39:10.150133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import the dataset","metadata":{}},{"cell_type":"code","source":"heart=pd.read_csv('../input/heart-disease/heart.csv')\nheart.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.15264Z","iopub.execute_input":"2022-01-09T12:39:10.152873Z","iopub.status.idle":"2022-01-09T12:39:10.190772Z","shell.execute_reply.started":"2022-01-09T12:39:10.152846Z","shell.execute_reply":"2022-01-09T12:39:10.189617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heart.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.192104Z","iopub.execute_input":"2022-01-09T12:39:10.192831Z","iopub.status.idle":"2022-01-09T12:39:10.199531Z","shell.execute_reply.started":"2022-01-09T12:39:10.192792Z","shell.execute_reply":"2022-01-09T12:39:10.198373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Exploration","metadata":{}},{"cell_type":"code","source":"#We have 13 features and one target variable (have disease or not ,1=yes, 0=no) for which we need to build a model\nheart.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.203292Z","iopub.execute_input":"2022-01-09T12:39:10.204159Z","iopub.status.idle":"2022-01-09T12:39:10.219952Z","shell.execute_reply.started":"2022-01-09T12:39:10.204092Z","shell.execute_reply":"2022-01-09T12:39:10.219332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Percentage of Patients Not Having Heart Disease: {:.2f}% \" .format(len(heart[heart.target==0])/(len(heart.target))*100))\nprint(\"Percentage of Patients Having Heart Disease: {:.2f}%\" .format (len(heart[heart.target==1])/(len(heart.target))*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.221256Z","iopub.execute_input":"2022-01-09T12:39:10.221828Z","iopub.status.idle":"2022-01-09T12:39:10.234894Z","shell.execute_reply.started":"2022-01-09T12:39:10.221796Z","shell.execute_reply":"2022-01-09T12:39:10.234322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking null values in the dataset\nheart.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.235986Z","iopub.execute_input":"2022-01-09T12:39:10.236349Z","iopub.status.idle":"2022-01-09T12:39:10.250218Z","shell.execute_reply.started":"2022-01-09T12:39:10.236319Z","shell.execute_reply":"2022-01-09T12:39:10.249604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for unique values in feature columns\nheart.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.252138Z","iopub.execute_input":"2022-01-09T12:39:10.252563Z","iopub.status.idle":"2022-01-09T12:39:10.268095Z","shell.execute_reply.started":"2022-01-09T12:39:10.252534Z","shell.execute_reply":"2022-01-09T12:39:10.267268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Datatype check for the dataframe\nheart.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.269267Z","iopub.execute_input":"2022-01-09T12:39:10.269598Z","iopub.status.idle":"2022-01-09T12:39:10.276934Z","shell.execute_reply.started":"2022-01-09T12:39:10.269571Z","shell.execute_reply":"2022-01-09T12:39:10.275907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Visualization for Target Variable","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='target',data=heart, palette=\"mako_r\")\nplt.xlabel(\"target(0 = no disease, 1= have disease)\")\nplt.ylabel(\"Count of People \")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.278371Z","iopub.execute_input":"2022-01-09T12:39:10.27874Z","iopub.status.idle":"2022-01-09T12:39:10.450968Z","shell.execute_reply.started":"2022-01-09T12:39:10.278712Z","shell.execute_reply":"2022-01-09T12:39:10.450081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating summary for feature columns","metadata":{}},{"cell_type":"code","source":"#UDF for summary\n\ndef summary_features(x):\n    return pd.Series([x.count(),x.isnull().sum(),x.sum(),x.mean(),x.median(),x.std(),\n                      x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),\n                      x.quantile(0.10),x.quantile(0.25),x.quantile(0.50),x.quantile(0.75),\n                      x.quantile(0.90),x.quantile(0.95), x.quantile(0.99),x.max()],\n                     index=['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'MIN', 'P1', \n                               'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.452488Z","iopub.execute_input":"2022-01-09T12:39:10.453536Z","iopub.status.idle":"2022-01-09T12:39:10.462268Z","shell.execute_reply.started":"2022-01-09T12:39:10.453479Z","shell.execute_reply":"2022-01-09T12:39:10.460921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features summary\ncols=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal']\nfeatures=heart[cols]\nfeatures.apply(summary_features)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.480934Z","iopub.execute_input":"2022-01-09T12:39:10.481341Z","iopub.status.idle":"2022-01-09T12:39:10.612645Z","shell.execute_reply.started":"2022-01-09T12:39:10.4813Z","shell.execute_reply":"2022-01-09T12:39:10.611694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model","metadata":{}},{"cell_type":"markdown","source":"##### data split for training and testing","metadata":{}},{"cell_type":"code","source":"# import the package\nfrom sklearn.model_selection import train_test_split\n\ntrain_X,test_X,train_Y,test_Y=train_test_split(heart[cols],heart['target'],test_size=0.3,random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.617025Z","iopub.execute_input":"2022-01-09T12:39:10.617429Z","iopub.status.idle":"2022-01-09T12:39:10.627566Z","shell.execute_reply.started":"2022-01-09T12:39:10.617384Z","shell.execute_reply":"2022-01-09T12:39:10.626576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Logistic Regression model","metadata":{"execution":{"iopub.status.busy":"2022-01-08T12:54:16.779475Z","iopub.execute_input":"2022-01-08T12:54:16.779912Z","iopub.status.idle":"2022-01-08T12:54:16.797255Z","shell.execute_reply.started":"2022-01-08T12:54:16.779879Z","shell.execute_reply":"2022-01-08T12:54:16.796297Z"}}},{"cell_type":"code","source":"#import the package\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score,classification_report,confusion_matrix,accuracy_score,roc_curve\naccuracies={}","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.629037Z","iopub.execute_input":"2022-01-09T12:39:10.62932Z","iopub.status.idle":"2022-01-09T12:39:10.63653Z","shell.execute_reply.started":"2022-01-09T12:39:10.629284Z","shell.execute_reply":"2022-01-09T12:39:10.635394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the model equation and fit the model on train data\nlogreg = LogisticRegression( max_iter = 1000 ).fit( train_X,train_Y )","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.640607Z","iopub.execute_input":"2022-01-09T12:39:10.641114Z","iopub.status.idle":"2022-01-09T12:39:10.832016Z","shell.execute_reply.started":"2022-01-09T12:39:10.641063Z","shell.execute_reply":"2022-01-09T12:39:10.83099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the coefficients for reference\npd.DataFrame( index = pd.Series(cols), data = logreg.coef_[0], columns = ['coefficient'] )","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.833625Z","iopub.execute_input":"2022-01-09T12:39:10.833972Z","iopub.status.idle":"2022-01-09T12:39:10.847567Z","shell.execute_reply.started":"2022-01-09T12:39:10.833924Z","shell.execute_reply":"2022-01-09T12:39:10.846523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy Score for Logistic Regression model\nprint(\"Logistic Regression Accuracy on Train Data: \",accuracy_score(train_Y,logreg.predict(train_X))*100)\nprint(\"Logistic Regression Accuracy on Test Data: \",accuracy_score(test_Y,logreg.predict(test_X))*100)\naccuracies['LogReg']=round((accuracy_score(test_Y,logreg.predict(test_X))*100),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.849148Z","iopub.execute_input":"2022-01-09T12:39:10.849515Z","iopub.status.idle":"2022-01-09T12:39:10.867651Z","shell.execute_reply.started":"2022-01-09T12:39:10.849467Z","shell.execute_reply":"2022-01-09T12:39:10.866623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Logistic Regression model works with 87% accuracy on Train data and with 81% accuracy on Test data","metadata":{}},{"cell_type":"markdown","source":"### 2) Building a KNN Model","metadata":{}},{"cell_type":"code","source":"#import the packages\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.868989Z","iopub.execute_input":"2022-01-09T12:39:10.869653Z","iopub.status.idle":"2022-01-09T12:39:10.874402Z","shell.execute_reply.started":"2022-01-09T12:39:10.869613Z","shell.execute_reply":"2022-01-09T12:39:10.87356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set the tuning parameters (k) for Grid Search CV\ntuned_param={'n_neighbors':range(2,10,1)}\n\n#Build th KNN model\nKNN_clf=GridSearchCV(KNeighborsClassifier(),tuned_param,cv=5,scoring='roc_auc').fit(train_X,train_Y)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:10.875635Z","iopub.execute_input":"2022-01-09T12:39:10.875861Z","iopub.status.idle":"2022-01-09T12:39:11.143938Z","shell.execute_reply.started":"2022-01-09T12:39:10.875833Z","shell.execute_reply":"2022-01-09T12:39:11.143302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking for best parameters for building the KNN model\nKNN_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.144942Z","iopub.execute_input":"2022-01-09T12:39:11.145447Z","iopub.status.idle":"2022-01-09T12:39:11.15012Z","shell.execute_reply.started":"2022-01-09T12:39:11.14541Z","shell.execute_reply":"2022-01-09T12:39:11.149583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building the KNN model with the best parameter  of n_neighbours=5\nKNN_clf=KNeighborsClassifier(n_neighbors=5).fit(train_X,train_Y)\n\n# get the model accuracy\n# get the model accuracy\nprint(\"KNN model Accuracy on train data : \",accuracy_score(train_Y,KNN_clf.predict(train_X))*100)\nprint(\"KNN model Accuracy on test data : \",accuracy_score(test_Y,KNN_clf.predict(test_X))*100)\naccuracies['KNN']=round((accuracy_score(test_Y,KNN_clf.predict(test_X))*100),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.151125Z","iopub.execute_input":"2022-01-09T12:39:11.151474Z","iopub.status.idle":"2022-01-09T12:39:11.18927Z","shell.execute_reply.started":"2022-01-09T12:39:11.151445Z","shell.execute_reply":"2022-01-09T12:39:11.188627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KNN model works with 76% accuracy on Train data and with 66% accuracy on Test data","metadata":{}},{"cell_type":"markdown","source":"#### 3) Building Support Vector Machine model","metadata":{}},{"cell_type":"code","source":"#import the package\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.190347Z","iopub.execute_input":"2022-01-09T12:39:11.190669Z","iopub.status.idle":"2022-01-09T12:39:11.193787Z","shell.execute_reply.started":"2022-01-09T12:39:11.19064Z","shell.execute_reply":"2022-01-09T12:39:11.193243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the SVM model\nsvm_clf=SVC(random_state=123).fit(train_X,train_Y)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.194822Z","iopub.execute_input":"2022-01-09T12:39:11.195292Z","iopub.status.idle":"2022-01-09T12:39:11.212919Z","shell.execute_reply.started":"2022-01-09T12:39:11.195261Z","shell.execute_reply":"2022-01-09T12:39:11.211788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the model accuracy\nprint(\"SVM model Accuracy on Train Data : \",accuracy_score(train_Y,svm_clf.predict(train_X))*100)\nprint(\"SVM model Accuracy on Test Data : \",accuracy_score(test_Y,svm_clf.predict(test_X))*100)\naccuracies['SVM']=round((accuracy_score(test_Y,svm_clf.predict(test_X))*100),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.214225Z","iopub.execute_input":"2022-01-09T12:39:11.214483Z","iopub.status.idle":"2022-01-09T12:39:11.230491Z","shell.execute_reply.started":"2022-01-09T12:39:11.214453Z","shell.execute_reply":"2022-01-09T12:39:11.229175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### SVM model works with 65% accuracy on Train data and test data","metadata":{}},{"cell_type":"markdown","source":"#### 4) Building Naive Bayes Model","metadata":{}},{"cell_type":"code","source":"#import the package\nfrom sklearn.naive_bayes import GaussianNB\n\n#Build the model\nnb_clf=GaussianNB()\nnb_clf.fit(train_X,train_Y)\n\n# get the Naive Bayes model accuracy\nprint(\"NB model Accuracy on Train Data : \",accuracy_score(train_Y,nb_clf.predict(train_X))*100)\nprint(\"NB model Accuracy on Test Data : \",accuracy_score(test_Y,nb_clf.predict(test_X))*100)\naccuracies['NaiveBayes']=round((accuracy_score(test_Y,nb_clf.predict(test_X))*100),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.231645Z","iopub.execute_input":"2022-01-09T12:39:11.232676Z","iopub.status.idle":"2022-01-09T12:39:11.256665Z","shell.execute_reply.started":"2022-01-09T12:39:11.232643Z","shell.execute_reply":"2022-01-09T12:39:11.255679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Naive Bayes model works with 85% accuracy on Train data and with 81% accuracy on Test data","metadata":{}},{"cell_type":"markdown","source":"#### 5)Building a Decision Tree Model","metadata":{}},{"cell_type":"code","source":"#import the package\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.259087Z","iopub.execute_input":"2022-01-09T12:39:11.259875Z","iopub.status.idle":"2022-01-09T12:39:11.264521Z","shell.execute_reply.started":"2022-01-09T12:39:11.25984Z","shell.execute_reply":"2022-01-09T12:39:11.263427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using Grid Search CV for hyperparameter tuning of maximum depth of tree\nparams={\"max_depth\":range(2,10)}\n\n#Build the decision tree model\nDt_clf=GridSearchCV(DecisionTreeClassifier(random_state=123),params,cv=5,scoring='roc_auc').fit(train_X,train_Y)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.266308Z","iopub.execute_input":"2022-01-09T12:39:11.26707Z","iopub.status.idle":"2022-01-09T12:39:11.566015Z","shell.execute_reply.started":"2022-01-09T12:39:11.267009Z","shell.execute_reply":"2022-01-09T12:39:11.564985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting the best param to build the Decision Tree model\nDt_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.568178Z","iopub.execute_input":"2022-01-09T12:39:11.568724Z","iopub.status.idle":"2022-01-09T12:39:11.575311Z","shell.execute_reply.started":"2022-01-09T12:39:11.568687Z","shell.execute_reply":"2022-01-09T12:39:11.574112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building the Decision model with the best parameter  of 'max_depth': 3\nDT_clf=DecisionTreeClassifier(max_depth=3,random_state=123).fit(train_X,train_Y)\n\n# get the model accuracy\n# get the model accuracy\nprint(\"Decision Tree model Accuracy on train data : \",accuracy_score(train_Y,DT_clf.predict(train_X))*100)\nprint(\"Decision Tree model Accuracy on test data : \",accuracy_score(test_Y,DT_clf.predict(test_X))*100)\naccuracies['DecisionTree']=round((accuracy_score(test_Y,DT_clf.predict(test_X))*100),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.576776Z","iopub.execute_input":"2022-01-09T12:39:11.576983Z","iopub.status.idle":"2022-01-09T12:39:11.599835Z","shell.execute_reply.started":"2022-01-09T12:39:11.576958Z","shell.execute_reply":"2022-01-09T12:39:11.598948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Decision Tree model works with 87% accuracy on Train data and with 80% accuracy on Test data","metadata":{}},{"cell_type":"markdown","source":"#### 6)Building the Random Forest Model","metadata":{}},{"cell_type":"code","source":"#Import the package\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:39:11.601166Z","iopub.execute_input":"2022-01-09T12:39:11.601621Z","iopub.status.idle":"2022-01-09T12:39:11.607178Z","shell.execute_reply.started":"2022-01-09T12:39:11.601578Z","shell.execute_reply":"2022-01-09T12:39:11.606166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Using Grid Search CV for hyperparameter tuning of maximum depth of tree\npargrid_rf = { 'n_estimators': range(100,1100,100)}\n\n# Build the random Forest model\nRf_clf=GridSearchCV(RandomForestClassifier(random_state=12),param_grid=pargrid_rf,cv=5,scoring='roc_auc',n_jobs=-1).fit(train_X,train_Y)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:50:24.623071Z","iopub.execute_input":"2022-01-09T12:50:24.624056Z","iopub.status.idle":"2022-01-09T12:50:46.558751Z","shell.execute_reply.started":"2022-01-09T12:50:24.624009Z","shell.execute_reply":"2022-01-09T12:50:46.55778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Getting the best param to build the Random Forest model\nRf_clf.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:51:27.199816Z","iopub.execute_input":"2022-01-09T12:51:27.200103Z","iopub.status.idle":"2022-01-09T12:51:27.207511Z","shell.execute_reply.started":"2022-01-09T12:51:27.200072Z","shell.execute_reply":"2022-01-09T12:51:27.206296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building the Random forest model with the best parameter  of 'n_estimators': 200\nRF_clf=RandomForestClassifier(n_estimators=200,random_state=123).fit(train_X,train_Y)\n\n# get the model accuracy\n# get the model accuracy\nprint(\"Random Forest model Accuracy on train data : \",accuracy_score(train_Y,RF_clf.predict(train_X))*100)\nprint(\"Random Forest model Accuracy on test data : \",accuracy_score(test_Y,RF_clf.predict(test_X))*100)\naccuracies['RandomForest']=round((accuracy_score(test_Y,RF_clf.predict(test_X))*100),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:55:30.846321Z","iopub.execute_input":"2022-01-09T12:55:30.846915Z","iopub.status.idle":"2022-01-09T12:55:31.317055Z","shell.execute_reply.started":"2022-01-09T12:55:30.846877Z","shell.execute_reply":"2022-01-09T12:55:31.316071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Forest model works with 100% accuracy on Train data and with 82% accuracy on Test data","metadata":{"execution":{"iopub.status.busy":"2022-01-09T12:55:44.515084Z","iopub.execute_input":"2022-01-09T12:55:44.515802Z","iopub.status.idle":"2022-01-09T12:55:44.52377Z","shell.execute_reply.started":"2022-01-09T12:55:44.515759Z","shell.execute_reply":"2022-01-09T12:55:44.523144Z"}}},{"cell_type":"code","source":"#Creating a Accuracy dataframe for different model\nAccuracy_model=pd.DataFrame([accuracies])\nAccuracies_model=Accuracy_model.T\nAccuracies_model.columns=['Accuracy']\nAccuracies_model","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:03:40.284565Z","iopub.execute_input":"2022-01-09T13:03:40.28489Z","iopub.status.idle":"2022-01-09T13:03:40.299338Z","shell.execute_reply.started":"2022-01-09T13:03:40.284858Z","shell.execute_reply":"2022-01-09T13:03:40.298478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = [\"red\", \"green\", \"orange\", \"pink\",\"yellow\",\"blue\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(20,10))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"Algorithms\")\nsns.barplot(x=Accuracies_model.index, y=Accuracies_model.Accuracy, palette=colors)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:08:08.344254Z","iopub.execute_input":"2022-01-09T13:08:08.344542Z","iopub.status.idle":"2022-01-09T13:08:08.555179Z","shell.execute_reply.started":"2022-01-09T13:08:08.344507Z","shell.execute_reply":"2022-01-09T13:08:08.554241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Our models work fine but best of them are Logreg ,NB and Random Forest with 81% of accuracy.","metadata":{}},{"cell_type":"markdown","source":"### Confusion Matrix for Various models","metadata":{}},{"cell_type":"code","source":"Log_cm=metrics.confusion_matrix(test_Y,logreg.predict(test_X))\nKNN_cm=metrics.confusion_matrix(test_Y,KNN_clf.predict(test_X))\nSVM_cm=metrics.confusion_matrix(test_Y,svm_clf.predict(test_X))\nNB_cm=metrics.confusion_matrix(test_Y,nb_clf.predict(test_X))\nDT_cm=metrics.confusion_matrix(test_Y,DT_clf.predict(test_X))\nRF_cm=metrics.confusion_matrix(test_Y,RF_clf.predict(test_X))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:15:15.860245Z","iopub.execute_input":"2022-01-09T13:15:15.860525Z","iopub.status.idle":"2022-01-09T13:15:15.908169Z","shell.execute_reply.started":"2022-01-09T13:15:15.860497Z","shell.execute_reply":"2022-01-09T13:15:15.907142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotting Confusion Matrices\nplt.figure(figsize=(24,12))\n\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\nplt.subplots_adjust(wspace = 0.4, hspace= 0.4)\n\nplt.subplot(2,3,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(Log_cm, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"] )\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.subplot(2,3,2)\nplt.title(\"K Nearest Neighbour Confusion Matrix\")\nsns.heatmap(KNN_cm, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"] )\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.subplot(2,3,3)\nplt.title(\"Support Vector Machine Confusion Matrix\")\nsns.heatmap(SVM_cm, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"] )\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.subplot(2,3,4)\nplt.title(\"Naive Bayes Confusion Matrix\")\nsns.heatmap(NB_cm, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"] )\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.subplot(2,3,5)\nplt.title(\"Decision Tree Confusion Matrix\")\nsns.heatmap(DT_cm, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"] )\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.subplot(2,3,6)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(RF_cm, annot=True,  fmt='.2f', xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"] )\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T13:23:22.216471Z","iopub.execute_input":"2022-01-09T13:23:22.216843Z","iopub.status.idle":"2022-01-09T13:23:23.94815Z","shell.execute_reply.started":"2022-01-09T13:23:22.216809Z","shell.execute_reply":"2022-01-09T13:23:23.947007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}